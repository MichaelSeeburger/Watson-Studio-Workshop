{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Part 2 (Optional): Use Spark and Python to Predict Equipment Purchase: Advanced analysis and Hyperparameter Tuning</b></th>\n",
    "      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n",
    "   </tr>\n",
    "   <tr style=\"border: none\">\n",
    "       <th style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/blob/master/spark/product-line-prediction/images/products_graphics.png?raw=true\" alt=\"Icon\"> </th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "You will learn how to:\n",
    "\n",
    "-  Load a CSV file into an Apache® Spark DataFrame.\n",
    "-  Analyze attributes of a dataset.\n",
    "-  Create an Apache® Spark machine learning pipeline.\n",
    "-  Train and evaluate a model.\n",
    "-  Tune hyperparameters of a model.\n",
    "-  Compare different models\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Attribute Analysis](#analyze)\n",
    "2.  [Hyperparameter tuning](#tune)\n",
    "3.  [Model comparison](#compare)\n",
    "4.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analyze\"></a>\n",
    "## 1. Attribute Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will load the data as an Apache® Spark DataFrame and explore the data.\n",
    "\n",
    "    1. Go to the 'Find and add data' panel on the right hand side panel\n",
    "    2. Find the shaped data asset 'Outdoor_Equipment_Sales.csv_shaped.csv'\n",
    "    3. Click on the 'Insert to code' dropdown\n",
    "    4. Select 'Insert SparkSession DataFrame'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20190607073125-0002\n",
      "KERNEL_ID = 1368dee6-e8d1-4036-9459-4e4df47f9353\n"
     ]
    }
   ],
   "source": [
    "## Insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we will load the data in another dataframe `df` and have a look at the data types and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `AGE` is in string type, but this is a numerical data, so we need to convert it to a numerical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df = df.withColumn(\"AGE\", df[\"AGE\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 48369\n",
      "Number of testing records : 12126\n"
     ]
    }
   ],
   "source": [
    "split_data = df.randomSplit([0.8, 0.2], 24)\n",
    "train_data = split_data[0]\n",
    "test_data = split_data[1]\n",
    "\n",
    "print('Number of training records: ' + str(train_data.count()))\n",
    "print('Number of testing records : ' + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Explore the attributes ¶\n",
    "\n",
    "Since 4 predictors are categorical, you can perform chi-squared tests on them. Chi-squared test can be performed when both the predictor and the target (label) are categorical. The goal of the chi-squared test is to assess the relationship between two categorical variables.\n",
    "\n",
    "In statistical hypothesis testing, the p-value or probability value or significance is, for a given statistical model, the probability that, when the null hypothesis is true, the statistical summary (such as the absolute value of the sample mean difference between two compared groups) would be greater than or equal to the actual observed results.\n",
    "\n",
    "In this method, as part of experimental design, before performing the experiment, one first chooses a model (the null hypothesis) and a threshold value for p, called the significance level of the test, traditionally 5% or 1% and denoted as α. If the p-value is less than the chosen significance level (α), that suggests that the observed data is sufficiently inconsistent with the null hypothesis and that the null hypothesis may be rejected. However, that does not prove that the tested hypothesis is true. When the p-value is calculated correctly, this test guarantees that the type I error rate is at most α. For typical analysis, using the standard α = 0.05 cutoff, the null hypothesis is rejected when p < .05 and not rejected when p > .05. The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis <a  href=\"https://en.wikipedia.org/wiki/P-value\" target=\"_blank\" rel=\"noopener no referrer\">[2]</a>.\n",
    "\n",
    "You will use scipy.stats module for the chi-squared test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chisquare method returns chi-squared test statistics and the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=99.30409124721051, pvalue=2.1656021491785304e-23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(df_pd['GENDER'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=18189.22479543764, pvalue=0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(df_pd['MARITAL_STATUS'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=60196.786908008915, pvalue=0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(df_pd['PROFESSION'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=24684.79775188032, pvalue=0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chisquare(df_pd['PRODUCT_LINE'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create cross-tabulation matrix for each predictor and get the chi-squared test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = ['Camping Equipment', 'Gold Equipment', 'Mountaineering Equipment', 'Outdoor Protection', 'Personal Accessories']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-tabulation matrix for predictor `GENDER` and target `PRODUCT_LINE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_gender = pd.crosstab(df_pd['PRODUCT_LINE'], df_pd['GENDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_gender_df = cont_gender\n",
    "cont_gender_df.index = target_classes\n",
    "cont_gender_df.index.name = 'PRODUCT_LINE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GENDER</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT_LINE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Camping Equipment</th>\n",
       "      <td>9429</td>\n",
       "      <td>14712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold Equipment</th>\n",
       "      <td>2256</td>\n",
       "      <td>4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mountaineering Equipment</th>\n",
       "      <td>3393</td>\n",
       "      <td>6665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor Protection</th>\n",
       "      <td>1924</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Accessories</th>\n",
       "      <td>12020</td>\n",
       "      <td>5246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GENDER                        F      M\n",
       "PRODUCT_LINE                          \n",
       "Camping Equipment          9429  14712\n",
       "Gold Equipment             2256   4228\n",
       "Mountaineering Equipment   3393   6665\n",
       "Outdoor Protection         1924    622\n",
       "Personal Accessories      12020   5246"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_gender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value of the output of the ` chi2_contingency` method is the chi-squared test statistics, the second values is the p-value, the third value it the degree of freedom, and the last value is the contingency table with expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6054.423628417609, 0.0, 4, array([[11581.45469874, 12559.54530126],\n",
       "        [ 3110.64795438,  3373.35204562],\n",
       "        [ 4825.24631788,  5232.75368212],\n",
       "        [ 1221.42345648,  1324.57654352],\n",
       "        [ 8283.22757253,  8982.77242747]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(cont_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `stats.chi2_contingency`, you can check if two features (predictors) are independent or not.\n",
    "\n",
    "$H_{0}$ (null hypothesis): Predictor $A$ and predictor $B$ are independent.  \n",
    "$H_{1}$ (alternative hypothesis): Predictor $A$ and predictor $B$ are dependent.\n",
    "\n",
    "If $p$ < $0.05$, then $A$ and $B$ are dependent, else $A$ and $B$ are independent.\n",
    "\n",
    "Since the $p$-value is $0.0$, $H_{0}$ (null hypothesis) is rejected - `GENDER` and `PRODUCT_LINE` are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-tabulation matrix for predictor `MARITAL_STATUS` and target `PRODUCT_LINE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_marital = pd.crosstab(df_pd['PRODUCT_LINE'], df_pd['MARITAL_STATUS'])\n",
    "cont_marital_df = cont_marital\n",
    "cont_marital_df.index = target_classes\n",
    "cont_marital_df.index.name = 'PRODUCT_LINE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>Married</th>\n",
       "      <th>Single</th>\n",
       "      <th>Unspecified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT_LINE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Camping Equipment</th>\n",
       "      <td>14332</td>\n",
       "      <td>8277</td>\n",
       "      <td>1532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold Equipment</th>\n",
       "      <td>4851</td>\n",
       "      <td>427</td>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mountaineering Equipment</th>\n",
       "      <td>2769</td>\n",
       "      <td>6619</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor Protection</th>\n",
       "      <td>1682</td>\n",
       "      <td>578</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Accessories</th>\n",
       "      <td>7258</td>\n",
       "      <td>8754</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "MARITAL_STATUS            Married  Single  Unspecified\n",
       "PRODUCT_LINE                                          \n",
       "Camping Equipment           14332    8277         1532\n",
       "Gold Equipment               4851     427         1206\n",
       "Mountaineering Equipment     2769    6619          670\n",
       "Outdoor Protection           1682     578          286\n",
       "Personal Accessories         7258    8754         1254"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_marital_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value of the output of the ` chi2_contingency` method is the chi-squared test statistics, the second values is the p-value, the third value it the degree of freedom, and the last value is the contingency table with expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7833.008344807513,\n",
       " 0.0,\n",
       " 8,\n",
       " array([[12327.69273494,  9838.76940243,  1974.53786263],\n",
       "        [ 3311.07906439,  2642.58236218,   530.33857344],\n",
       "        [ 5136.15564923,  4099.18158525,   822.66276552],\n",
       "        [ 1300.12450616,  1037.63335813,   208.24213571],\n",
       "        [ 8816.94804529,  7036.83329201,  1412.2186627 ]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(cont_marital)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `stats.chi2_contingency`, you can check if two features (predictors) are independent or not.\n",
    "\n",
    "$H_{0}$ (null hypothesis): Predictor $A$ and predictor $B$ are independent.  \n",
    "$H_{1}$ (alternative hypothesis): Predictor $A$ and predictor $B$ are dependent.\n",
    "\n",
    "If $p$ < $0.05$, then $A$ and $B$ are dependent, else $A$ and $B$ are independent.\n",
    "\n",
    "Since the $p$-value is $0.0$, $H_{0}$ (null hypothesis) is rejected - `MARITAL_STATUS` and `PRODUCT_LINE` are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-tabulation matrix for predictor `PROFESSION` and target `PRODUCT_LINE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_profession = pd.crosstab(df_pd['PRODUCT_LINE'], df_pd['PROFESSION'])\n",
    "cont_profession_df = cont_profession\n",
    "cont_profession_df.index = target_classes\n",
    "cont_profession_df.index.name = 'PRODUCT_LINE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PROFESSION</th>\n",
       "      <th>Executive</th>\n",
       "      <th>Hospitality</th>\n",
       "      <th>Other</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Retired</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Student</th>\n",
       "      <th>Trades</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCT_LINE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Camping Equipment</th>\n",
       "      <td>3775</td>\n",
       "      <td>1977</td>\n",
       "      <td>9684</td>\n",
       "      <td>1866</td>\n",
       "      <td>619</td>\n",
       "      <td>30</td>\n",
       "      <td>3452</td>\n",
       "      <td>505</td>\n",
       "      <td>2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold Equipment</th>\n",
       "      <td>175</td>\n",
       "      <td>459</td>\n",
       "      <td>3477</td>\n",
       "      <td>1025</td>\n",
       "      <td>21</td>\n",
       "      <td>443</td>\n",
       "      <td>357</td>\n",
       "      <td>54</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mountaineering Equipment</th>\n",
       "      <td>499</td>\n",
       "      <td>83</td>\n",
       "      <td>4044</td>\n",
       "      <td>2142</td>\n",
       "      <td>449</td>\n",
       "      <td>14</td>\n",
       "      <td>1273</td>\n",
       "      <td>815</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outdoor Protection</th>\n",
       "      <td>292</td>\n",
       "      <td>303</td>\n",
       "      <td>1140</td>\n",
       "      <td>136</td>\n",
       "      <td>179</td>\n",
       "      <td>124</td>\n",
       "      <td>79</td>\n",
       "      <td>220</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Accessories</th>\n",
       "      <td>1152</td>\n",
       "      <td>502</td>\n",
       "      <td>6261</td>\n",
       "      <td>3801</td>\n",
       "      <td>1522</td>\n",
       "      <td>578</td>\n",
       "      <td>1576</td>\n",
       "      <td>1365</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PROFESSION                Executive  Hospitality  Other  Professional  Retail  \\\n",
       "PRODUCT_LINE                                                                    \n",
       "Camping Equipment              3775         1977   9684          1866     619   \n",
       "Gold Equipment                  175          459   3477          1025      21   \n",
       "Mountaineering Equipment        499           83   4044          2142     449   \n",
       "Outdoor Protection              292          303   1140           136     179   \n",
       "Personal Accessories           1152          502   6261          3801    1522   \n",
       "\n",
       "PROFESSION                Retired  Sales  Student  Trades  \n",
       "PRODUCT_LINE                                               \n",
       "Camping Equipment              30   3452      505    2233  \n",
       "Gold Equipment                443    357       54     473  \n",
       "Mountaineering Equipment       14   1273      815     739  \n",
       "Outdoor Protection            124     79      220      73  \n",
       "Personal Accessories          578   1576     1365     509  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_profession_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first value of the output of the ` chi2_contingency` method is the chi-squared test statistics, the second values is the p-value, the third value it the degree of freedom, and the last value is the contingency table with expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10305.783485396083,\n",
       " 0.0,\n",
       " 32,\n",
       " array([[2351.64745847, 1326.46803868, 9819.21557153, 3579.54822713,\n",
       "         1113.3711877 ,  474.47969254, 2688.45221919, 1180.8119514 ,\n",
       "         1607.00565336],\n",
       "        [ 631.62595256,  356.27433672, 2637.330424  ,  961.42623357,\n",
       "          299.03892884,  127.43988759,  722.08790809,  317.15275643,\n",
       "          431.6235722 ],\n",
       "        [ 979.78004794,  552.6538061 , 4091.0347632 , 1491.36722043,\n",
       "          463.87007191,  197.685131  , 1120.10490123,  491.9682949 ,\n",
       "          669.53576329],\n",
       "        [ 248.01352178,  139.89427225, 1035.57113811,  377.5125217 ,\n",
       "          117.42028267,   50.04040003,  283.53420944,  124.53283742,\n",
       "          169.4808166 ],\n",
       "        [1681.93301926,  948.70954624, 7022.84810315, 2560.14579717,\n",
       "          796.29952889,  339.35488883, 1922.82076205,  844.53415985,\n",
       "         1149.35419456]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(cont_profession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `stats.chi2_contingency`, you can check if two features (predictors) are independent or not.\n",
    "\n",
    "$H_{0}$ (null hypothesis): Predictor $A$ and predictor $B$ are independent.  \n",
    "$H_{1}$ (alternative hypothesis): Predictor $A$ and predictor $B$ are dependent.\n",
    "\n",
    "If $p$ < $0.05$, then $A$ and $B$ are dependent, else $A$ and $B$ are independent.\n",
    "\n",
    "Since the $p$-value is $0.0$, $H_{0}$ (null hypothesis) is rejected - `PROFESSIONS` and `PRODUCT_LINE` are dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therefore we may conclude that the categorical attribites we explored have direct dependency on the `PRODUCT_LINE`, therefore it would be logical to consider them for predicting the `PRODUCT_LINE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tuning\"></a>\n",
    "## 2. Hyperparameter Tuning\n",
    "\n",
    "In this step we will tune the parameters of a model to select the best parameters to achieve highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create the pipeline<a id=\"pipe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, you will create an Apache® Spark machine learning pipeline and train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step, you need to import the Apache® Spark machine learning modules that will be needed in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import numpy as np\n",
    "from pyspark.ml.tuning import CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, use the `StringIndexer` transformer to convert all string fields into numerical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer_label = StringIndexer(inputCol='PRODUCT_LINE', outputCol='label').fit(df)\n",
    "stringIndexer_prof = StringIndexer(inputCol='PROFESSION', outputCol='PROFESSION_IX')\n",
    "stringIndexer_gend = StringIndexer(inputCol='GENDER', outputCol='GENDER_IX')\n",
    "stringIndexer_mar = StringIndexer(inputCol='MARITAL_STATUS', outputCol='MARITAL_STATUS_IX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, create a feature vector to combine all features (predictors) together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler_features = VectorAssembler(inputCols=['GENDER_IX', 'AGE', 'MARITAL_STATUS_IX', 'PROFESSION_IX'], outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a `Random Forest Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, convert the indexed labels back to original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelConverter = IndexToString(inputCol='prediction', outputCol='predictedLabel', labels=stringIndexer_label.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we sill build the pipeline. A pipeline consists of transformers and an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stringIndexer_label, stringIndexer_prof, stringIndexer_gend, stringIndexer_mar,vectorAssembler_features, rf, labelConverter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 Create a parameter grid\n",
    "\n",
    "In this subsection, we will create a grid of paramaters and train the model multiple times to check which parameters give us the best accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use a `ParamGridBuilder` to construct a grid of parameters to search over. It will try all combinations of values of two parameters `numTrees` and `maxDepth` and determine best model using the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [int(x) for x in np.linspace(start = 10, stop = 50, num = 3)]) \\\n",
    "    .addGrid(rf.maxDepth, [int(x) for x in np.linspace(start = 5, stop = 30, num = 3)]) \\\n",
    ".build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(),\n",
    "numFolds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next step we will cross validate against training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the best selected model achieved an accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 58.12%\n",
      "Test Error = 41.88%\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Accuracy = {:.2f}%'.format(accuracy*100))\n",
    "print('Test Error = {:.2f}%'.format((1.0 - accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Now we can see which parameters gave us the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipeline = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_4d97bfab309ca7e974d5,\n",
       " StringIndexer_4bea95623432f96644b5,\n",
       " StringIndexer_40f8b033bff79943a767,\n",
       " StringIndexer_4fadb77431afead94fe6,\n",
       " VectorAssembler_4fa7813a47805614ef97,\n",
       " RandomForestClassificationModel (uid=RandomForestClassifier_4c2b9c9397b1f6ed7622) with 50 trees]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestPipeline.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = bestPipeline.stages[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numTrees -  50\n",
      "maxDepth -  17\n"
     ]
    }
   ],
   "source": [
    "print('numTrees - ', bestModel.getNumTrees)\n",
    "print('maxDepth - ', bestModel.getOrDefault('maxDepth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Therefore we may conclude to have the best `RandomForestClassifier` model, we will have to use the parameters `numTrees` & `maxDepth` with the value that we have obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compare\"></a>\n",
    "## 3. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will train some more classification models with the same training data and evaluate their performance against the first trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 DecisionTreeClassifier\n",
    "\n",
    "A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. It partitions the tree in recursively manner call recursive partitioning<a  href=\"https://www.datacamp.com/community/tutorials/decision-tree-classification-python\" target=\"_blank\" rel=\"noopener no referrer\">[3]</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline_dt = Pipeline(stages=[stringIndexer_label, stringIndexer_prof, stringIndexer_gend, stringIndexer_mar, vectorAssembler_features, dt, labelConverter])\n",
    "model_dt = pipeline_dt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 55.62%\n",
      "Test Error = 44.38%\n"
     ]
    }
   ],
   "source": [
    "predictions = model_dt.transform(test_data)\n",
    "evaluatorDT = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluatorDT.evaluate(predictions)\n",
    "\n",
    "print('Accuracy = {:.2f}%'.format(accuracy*100))\n",
    "print('Test Error = {:.2f}%'.format((1.0 - accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MultilayerPerceptronClassifier\n",
    "\n",
    "The Multilayer perceptron classifier (MLPC) is a classifier based on the feedforward artificial neural network in the current implementation of Spark ML API. The MLPC employs backpropagation for learning the model. Technically, Spark used the logistic loss function for optimization and L-BFGS as an optimization routine. The number of nodes (say) N in the output layer corresponds to the number of classes <a  href=\"https://dzone.com/articles/deep-learning-via-multilayer-perceptron-classifier\" target=\"_blank\" rel=\"noopener no referrer\">[4]</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "layers = [4, 5, 4, 5]\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "pipeline_mpc = Pipeline(stages=[stringIndexer_label, stringIndexer_prof, stringIndexer_gend, stringIndexer_mar, vectorAssembler_features, trainer, labelConverter])\n",
    "model_mpc = pipeline_mpc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 47.52%\n",
      "Test Error = 52.48%\n"
     ]
    }
   ],
   "source": [
    "predictions = model_mpc.transform(test_data)\n",
    "evaluatorMPC = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluatorMPC.evaluate(predictions)\n",
    "\n",
    "print('Accuracy = {:.2f}%'.format(accuracy*100))\n",
    "print('Test Error = {:.2f}%'.format((1.0 - accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we have now trained and evaluated two more models. We therefore are in a position to confidently select the best model that we have and use it to predict equipment purchase of customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 4. Summary and next steps     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You successfully completed this notebook! \n",
    " \n",
    "You learned how to use Apache® Spark Machine Learning for model creation and evaluation. \n",
    "\n",
    "You also learned how to tune parameters of a model, and how to select the best model for your purpose after comparing multiple models.\n",
    " \n",
    "Check out our [Online Documentation](https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html) for more samples, tutorials, documentation, how-tos, and blog posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Lukasz Cmielowski**, Ph.D., is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge.  \n",
    "**Jihyoung Kim**, Ph.D., is a Data Scientist at IBM who strives to make data science easy for everyone through Watson Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017-2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
